{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Variational Autoencoder for generating cat images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from src.model import genModel\n",
    "from src.vaeHelpers import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Load the data, create a training/validation split. Save the split to a file to help with continuation of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFresh = False\n",
    "\n",
    "if ( trainFresh ):\n",
    "    catFiles = np.array( glob('./catCroped/*.jpg') )\n",
    "    \n",
    "    valFrac = 0.1\n",
    "    n = len(catFiles)\n",
    "    \n",
    "    inds = np.random.permutation( len(catFiles) )\n",
    "    trainInds, valInds = inds[ : -int(n*valFrac) ], inds[ -int(n*valFrac) : ]\n",
    "    \n",
    "    train, val = catFiles[ trainInds ], catFiles[ valInds ]\n",
    "    \n",
    "    writeFilesList( \"trainFiles.txt\", train )\n",
    "    writeFilesList( \"valFiles.txt\", val )\n",
    "\n",
    "else:\n",
    "    val   = readSavedFiles( \"valFiles.txt\" )\n",
    "    train = readSavedFiles( \"trainFiles.txt\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 2048), (None, 204 12621608  \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 256, 256, 3)       8431379   \n",
      "=================================================================\n",
      "Total params: 21,052,987\n",
      "Trainable params: 21,040,235\n",
      "Non-trainable params: 12,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batchSize = 16\n",
    "imgSize = 256\n",
    "\n",
    "encoder, decoder, VAE = genModel()\n",
    "VAE.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "  1/575 [..............................] - ETA: 7:19:07 - loss: 1718.6731"
     ]
    }
   ],
   "source": [
    "if ( not trainFresh ):\n",
    "    VAE.load_weights( \"weights/catGen.hdf5\" )\n",
    "\n",
    "earlyStopper = EarlyStopping( patience = 50, verbose = 1 )\n",
    "checkPointer = ModelCheckpoint( filepath = \"weights/catGen.hdf5\", save_best_only = True, verbose = 1 )\n",
    "rateReduce   = ReduceLROnPlateau( monitor = 'val_loss', factor = 0.5, patience = 20, cooldown = 5 )\n",
    "\n",
    "losses = VAE.fit_generator( genBatch( train, batchSize, imgSize, True ),\n",
    "                   validation_data = genBatch( val, batchSize, imgSize, False ),\n",
    "                   epochs = 5000,\n",
    "                   validation_steps = len(val)   // batchSize,\n",
    "                   steps_per_epoch  = len(train) // batchSize,\n",
    "                   callbacks = [ earlyStopper, checkPointer ] )\n",
    "                   #callbacks = [ earlyStopper, checkPointer, rateReduce ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLosses( losses.history )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
