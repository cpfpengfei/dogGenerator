{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Variational Autoencoder for generating cat images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from src.model import genModel\n",
    "from src.vaeHelpers import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Load the data, create a training/validation split. Save the split to a file to help with continuation of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFresh = True\n",
    "\n",
    "if ( trainFresh ):\n",
    "    catFiles = np.array( glob('./catCropedBetter/*.jpg') )\n",
    "    \n",
    "    valFrac = 0.1\n",
    "    n = len(catFiles)\n",
    "    \n",
    "    inds = np.random.permutation( len(catFiles) )\n",
    "    trainInds, valInds = inds[ : -int(n*valFrac) ], inds[ -int(n*valFrac) : ]\n",
    "    \n",
    "    train, val = catFiles[ trainInds ], catFiles[ valInds ]\n",
    "    \n",
    "    writeFilesList( \"trainCats.txt\", train )\n",
    "    writeFilesList( \"valCats.txt\", val )\n",
    "\n",
    "else:\n",
    "    val   = readSavedFiles( \"valFiles.txt\" )\n",
    "    train = readSavedFiles( \"trainFiles.txt\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 2048), (None, 204 16814392  \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 128, 128, 3)       12632191  \n",
      "=================================================================\n",
      "Total params: 29,446,583\n",
      "Trainable params: 29,429,841\n",
      "Non-trainable params: 16,742\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baxter/Desktop/MLbook/catGenerator/src/model.py:96: UserWarning: Output \"decoder\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"decoder\" during training.\n",
      "  VAE.compile( optimizer = opt, loss = None )\n"
     ]
    }
   ],
   "source": [
    "batchSize = 64\n",
    "imgSize = 128\n",
    "\n",
    "encoder, decoder, VAE = genModel( imgSize = 128, lossType = \"mse\" )\n",
    "VAE.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 3266.7084\n",
      "Epoch 00001: val_loss improved from inf to 1881.48892, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 23s 166ms/step - loss: 3266.2811 - val_loss: 1881.4889\n",
      "Epoch 2/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 1909.6552\n",
      "Epoch 00002: val_loss improved from 1881.48892 to 1017.62392, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 144ms/step - loss: 1904.7376 - val_loss: 1017.6239\n",
      "Epoch 3/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 1599.9708\n",
      "Epoch 00003: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 1596.4964 - val_loss: 7976.7281\n",
      "Epoch 4/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 1206.9495\n",
      "Epoch 00004: val_loss improved from 1017.62392 to 766.22519, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 21s 147ms/step - loss: 1203.3542 - val_loss: 766.2252\n",
      "Epoch 5/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 1235.4732\n",
      "Epoch 00005: val_loss improved from 766.22519 to 657.30779, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 1237.8102 - val_loss: 657.3078\n",
      "Epoch 6/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 845.5789\n",
      "Epoch 00006: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 845.5888 - val_loss: 931.1262\n",
      "Epoch 7/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 935.3787\n",
      "Epoch 00007: val_loss improved from 657.30779 to 572.94779, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 144ms/step - loss: 933.6715 - val_loss: 572.9478\n",
      "Epoch 8/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 848.7340\n",
      "Epoch 00008: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 849.9691 - val_loss: 727.9607\n",
      "Epoch 9/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 893.3369\n",
      "Epoch 00009: val_loss improved from 572.94779 to 549.05655, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 21s 150ms/step - loss: 894.2273 - val_loss: 549.0565\n",
      "Epoch 10/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 832.9978\n",
      "Epoch 00010: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 831.1522 - val_loss: 555.0298\n",
      "Epoch 11/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 859.3361\n",
      "Epoch 00011: val_loss did not improve\n",
      "140/140 [==============================] - 19s 134ms/step - loss: 863.0006 - val_loss: 826.9174\n",
      "Epoch 12/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 828.3569\n",
      "Epoch 00012: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 829.7504 - val_loss: 865.8829\n",
      "Epoch 13/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 748.2419\n",
      "Epoch 00013: val_loss improved from 549.05655 to 494.72957, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 146ms/step - loss: 747.7577 - val_loss: 494.7296\n",
      "Epoch 14/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 803.7233\n",
      "Epoch 00014: val_loss did not improve\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 802.6123 - val_loss: 571.2758\n",
      "Epoch 15/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 868.5883\n",
      "Epoch 00015: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 866.3355 - val_loss: 538.1945\n",
      "Epoch 16/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 727.4033\n",
      "Epoch 00016: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 726.7849 - val_loss: 500.5450\n",
      "Epoch 17/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 828.7046\n",
      "Epoch 00017: val_loss did not improve\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 835.3518 - val_loss: 538.6164\n",
      "Epoch 18/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 729.2515\n",
      "Epoch 00018: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 729.6906 - val_loss: 1370.9070\n",
      "Epoch 19/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 761.5391\n",
      "Epoch 00019: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 765.7128 - val_loss: 518.4135\n",
      "Epoch 20/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 752.0847\n",
      "Epoch 00020: val_loss improved from 494.72957 to 464.42930, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 21s 149ms/step - loss: 752.0156 - val_loss: 464.4293\n",
      "Epoch 21/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 766.5808\n",
      "Epoch 00021: val_loss did not improve\n",
      "140/140 [==============================] - 19s 134ms/step - loss: 765.6371 - val_loss: 519.5020\n",
      "Epoch 22/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 720.6172\n",
      "Epoch 00022: val_loss improved from 464.42930 to 452.95040, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 718.8676 - val_loss: 452.9504\n",
      "Epoch 23/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 704.5808\n",
      "Epoch 00023: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 703.3391 - val_loss: 458.7288\n",
      "Epoch 24/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 697.3170\n",
      "Epoch 00024: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 695.6388 - val_loss: 491.6085\n",
      "Epoch 25/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 696.1973\n",
      "Epoch 00025: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 695.1439 - val_loss: 466.6107\n",
      "Epoch 26/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 669.6540\n",
      "Epoch 00026: val_loss did not improve\n",
      "140/140 [==============================] - 19s 134ms/step - loss: 668.0426 - val_loss: 465.8939\n",
      "Epoch 27/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 740.4717\n",
      "Epoch 00027: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 740.2013 - val_loss: 461.3601\n",
      "Epoch 28/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 696.3101\n",
      "Epoch 00028: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 694.5245 - val_loss: 481.7886\n",
      "Epoch 29/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 688.9213\n",
      "Epoch 00029: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 698.0192 - val_loss: 496.8265\n",
      "Epoch 30/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 754.7460\n",
      "Epoch 00030: val_loss did not improve\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 757.3564 - val_loss: 3099.2438\n",
      "Epoch 31/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 755.7232\n",
      "Epoch 00031: val_loss did not improve\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 753.6672 - val_loss: 485.5868\n",
      "Epoch 32/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 653.4675\n",
      "Epoch 00032: val_loss improved from 452.95040 to 419.58995, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 652.9538 - val_loss: 419.5899\n",
      "Epoch 33/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 662.0535\n",
      "Epoch 00033: val_loss improved from 419.58995 to 411.73921, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 21s 148ms/step - loss: 660.7863 - val_loss: 411.7392\n",
      "Epoch 34/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 685.4206\n",
      "Epoch 00034: val_loss improved from 411.73921 to 408.53303, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 683.5293 - val_loss: 408.5330\n",
      "Epoch 35/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 665.6964\n",
      "Epoch 00035: val_loss did not improve\n",
      "140/140 [==============================] - 21s 147ms/step - loss: 663.9805 - val_loss: 627.3576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 633.6420\n",
      "Epoch 00036: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 632.7746 - val_loss: 428.0499\n",
      "Epoch 37/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 660.4444\n",
      "Epoch 00037: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 659.4640 - val_loss: 425.2462\n",
      "Epoch 38/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 679.8299\n",
      "Epoch 00038: val_loss improved from 408.53303 to 396.14516, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 144ms/step - loss: 678.2919 - val_loss: 396.1452\n",
      "Epoch 39/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 642.0622\n",
      "Epoch 00039: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 640.6343 - val_loss: 423.7830\n",
      "Epoch 40/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 646.7006\n",
      "Epoch 00040: val_loss improved from 396.14516 to 389.62459, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 144ms/step - loss: 645.1253 - val_loss: 389.6246\n",
      "Epoch 41/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 633.7413\n",
      "Epoch 00041: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 635.4532 - val_loss: 402.5706\n",
      "Epoch 42/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 647.4248\n",
      "Epoch 00042: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 647.2868 - val_loss: 402.3791\n",
      "Epoch 43/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 687.0671\n",
      "Epoch 00043: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 685.5231 - val_loss: 404.5486\n",
      "Epoch 44/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 618.2754\n",
      "Epoch 00044: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 620.5774 - val_loss: 413.2869\n",
      "Epoch 45/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 649.1098\n",
      "Epoch 00045: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 647.2612 - val_loss: 391.7463\n",
      "Epoch 46/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 641.0699\n",
      "Epoch 00046: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 640.1426 - val_loss: 395.6393\n",
      "Epoch 47/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 585.0661\n",
      "Epoch 00047: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 584.2491 - val_loss: 399.2048\n",
      "Epoch 48/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 658.7276\n",
      "Epoch 00048: val_loss did not improve\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 664.5527 - val_loss: 432.9215\n",
      "Epoch 49/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 659.2381\n",
      "Epoch 00049: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 659.2081 - val_loss: 848.4061\n",
      "Epoch 50/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 630.3395\n",
      "Epoch 00050: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 636.6151 - val_loss: 429.4139\n",
      "Epoch 51/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 591.3649\n",
      "Epoch 00051: val_loss did not improve\n",
      "140/140 [==============================] - 18s 131ms/step - loss: 597.4797 - val_loss: 406.0458\n",
      "Epoch 52/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 652.8080\n",
      "Epoch 00052: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 651.2792 - val_loss: 434.4988\n",
      "Epoch 53/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 669.8015\n",
      "Epoch 00053: val_loss did not improve\n",
      "140/140 [==============================] - 20s 146ms/step - loss: 667.9259 - val_loss: 428.0365\n",
      "Epoch 54/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 572.4005\n",
      "Epoch 00054: val_loss improved from 389.62459 to 375.87605, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 577.5488 - val_loss: 375.8761\n",
      "Epoch 55/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 616.4231\n",
      "Epoch 00055: val_loss did not improve\n",
      "140/140 [==============================] - 20s 139ms/step - loss: 615.0831 - val_loss: 432.1767\n",
      "Epoch 56/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 690.6128\n",
      "Epoch 00056: val_loss did not improve\n",
      "140/140 [==============================] - 19s 133ms/step - loss: 689.7870 - val_loss: 492.3373\n",
      "Epoch 57/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 598.6918\n",
      "Epoch 00057: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 597.2325 - val_loss: 414.0971\n",
      "Epoch 58/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 590.2251\n",
      "Epoch 00058: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 588.7833 - val_loss: 390.3615\n",
      "Epoch 59/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 589.3552\n",
      "Epoch 00059: val_loss did not improve\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 588.2078 - val_loss: 384.9532\n",
      "Epoch 60/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 573.3400\n",
      "Epoch 00060: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 579.8953 - val_loss: 384.2872\n",
      "Epoch 61/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 597.5797\n",
      "Epoch 00061: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 596.1791 - val_loss: 386.8408\n",
      "Epoch 62/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 575.4716\n",
      "Epoch 00062: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 578.0279 - val_loss: 384.9508\n",
      "Epoch 63/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 616.1961\n",
      "Epoch 00063: val_loss did not improve\n",
      "140/140 [==============================] - 21s 147ms/step - loss: 614.9249 - val_loss: 376.1730\n",
      "Epoch 64/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 619.5872\n",
      "Epoch 00064: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 624.3698 - val_loss: 389.3010\n",
      "Epoch 65/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 558.0221\n",
      "Epoch 00065: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 557.2165 - val_loss: 385.8222\n",
      "Epoch 66/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 583.5650\n",
      "Epoch 00066: val_loss did not improve\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 581.9234 - val_loss: 389.2783\n",
      "Epoch 67/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 581.8928\n",
      "Epoch 00067: val_loss improved from 375.87605 to 374.81804, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 580.9290 - val_loss: 374.8180\n",
      "Epoch 68/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 626.5346\n",
      "Epoch 00068: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 626.6827 - val_loss: 382.0945\n",
      "Epoch 69/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 579.2784\n",
      "Epoch 00069: val_loss improved from 374.81804 to 371.34888, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 146ms/step - loss: 577.6860 - val_loss: 371.3489\n",
      "Epoch 70/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 598.0678\n",
      "Epoch 00070: val_loss improved from 371.34888 to 367.04692, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 596.7370 - val_loss: 367.0469\n",
      "Epoch 71/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 554.7782\n",
      "Epoch 00071: val_loss improved from 367.04692 to 362.04706, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 19s 134ms/step - loss: 553.7298 - val_loss: 362.0471\n",
      "Epoch 72/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/140 [============================>.] - ETA: 0s - loss: 589.4853\n",
      "Epoch 00072: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 588.1622 - val_loss: 379.5619\n",
      "Epoch 73/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 572.4446\n",
      "Epoch 00073: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 572.8859 - val_loss: 376.8129\n",
      "Epoch 74/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 564.1704\n",
      "Epoch 00074: val_loss did not improve\n",
      "140/140 [==============================] - 18s 132ms/step - loss: 562.9517 - val_loss: 384.4874\n",
      "Epoch 75/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 574.1214\n",
      "Epoch 00075: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 573.0138 - val_loss: 377.3790\n",
      "Epoch 76/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 579.7776\n",
      "Epoch 00076: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 578.3081 - val_loss: 371.6189\n",
      "Epoch 77/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 570.3960\n",
      "Epoch 00077: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 569.1040 - val_loss: 372.6149\n",
      "Epoch 78/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 591.0210\n",
      "Epoch 00078: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 589.4411 - val_loss: 372.6230\n",
      "Epoch 79/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 560.6646\n",
      "Epoch 00079: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 560.0260 - val_loss: 376.2382\n",
      "Epoch 80/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 561.7796\n",
      "Epoch 00080: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 562.9074 - val_loss: 363.8912\n",
      "Epoch 81/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 565.3239\n",
      "Epoch 00081: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 571.3319 - val_loss: 371.0207\n",
      "Epoch 82/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 526.5903\n",
      "Epoch 00082: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 525.4709 - val_loss: 363.4700\n",
      "Epoch 83/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 593.5658\n",
      "Epoch 00083: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 597.4806 - val_loss: 379.4817\n",
      "Epoch 84/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 505.0892\n",
      "Epoch 00084: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 504.2431 - val_loss: 365.7189\n",
      "Epoch 85/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 593.1064\n",
      "Epoch 00085: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 591.5055 - val_loss: 384.4171\n",
      "Epoch 86/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 607.0711\n",
      "Epoch 00086: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 607.6660 - val_loss: 370.4293\n",
      "Epoch 87/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 587.2644\n",
      "Epoch 00087: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 592.7565 - val_loss: 364.3450\n",
      "Epoch 88/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 568.5607\n",
      "Epoch 00088: val_loss improved from 362.04706 to 360.29757, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 21s 148ms/step - loss: 567.1718 - val_loss: 360.2976\n",
      "Epoch 89/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 643.4997\n",
      "Epoch 00089: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 641.7351 - val_loss: 368.5124\n",
      "Epoch 90/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 614.5664\n",
      "Epoch 00090: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 613.4512 - val_loss: 366.2361\n",
      "Epoch 91/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 550.6499\n",
      "Epoch 00091: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 549.1971 - val_loss: 369.4658\n",
      "Epoch 92/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 573.6973\n",
      "Epoch 00092: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 572.4808 - val_loss: 360.9077\n",
      "Epoch 93/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 614.1833\n",
      "Epoch 00093: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 615.1027 - val_loss: 440.0159\n",
      "Epoch 94/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 547.6934\n",
      "Epoch 00094: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 546.5546 - val_loss: 366.3880\n",
      "Epoch 95/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 614.5708\n",
      "Epoch 00095: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 612.6378 - val_loss: 368.5202\n",
      "Epoch 96/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 572.6537\n",
      "Epoch 00096: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 571.1121 - val_loss: 364.2657\n",
      "Epoch 97/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 560.4650\n",
      "Epoch 00097: val_loss improved from 360.29757 to 356.92119, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 21s 147ms/step - loss: 559.1247 - val_loss: 356.9212\n",
      "Epoch 98/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 603.2651\n",
      "Epoch 00098: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 601.6976 - val_loss: 363.6838\n",
      "Epoch 99/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 538.7346\n",
      "Epoch 00099: val_loss did not improve\n",
      "140/140 [==============================] - 20s 146ms/step - loss: 537.6627 - val_loss: 363.9558\n",
      "Epoch 100/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 570.5508\n",
      "Epoch 00100: val_loss improved from 356.92119 to 354.70897, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 145ms/step - loss: 571.7483 - val_loss: 354.7090\n",
      "Epoch 101/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 623.6798\n",
      "Epoch 00101: val_loss did not improve\n",
      "140/140 [==============================] - 19s 133ms/step - loss: 621.9205 - val_loss: 374.1384\n",
      "Epoch 102/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 604.7639\n",
      "Epoch 00102: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 602.9508 - val_loss: 358.1589\n",
      "Epoch 103/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 575.4015\n",
      "Epoch 00103: val_loss did not improve\n",
      "140/140 [==============================] - 21s 147ms/step - loss: 574.0314 - val_loss: 366.9286\n",
      "Epoch 104/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 590.6478\n",
      "Epoch 00104: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 589.1679 - val_loss: 373.9523\n",
      "Epoch 105/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 568.9667\n",
      "Epoch 00105: val_loss improved from 354.70897 to 348.84995, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 145ms/step - loss: 567.4774 - val_loss: 348.8500\n",
      "Epoch 106/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 599.2455\n",
      "Epoch 00106: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 597.3047 - val_loss: 359.1729\n",
      "Epoch 107/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 614.3628\n",
      "Epoch 00107: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 612.6670 - val_loss: 386.6116\n",
      "Epoch 108/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 568.3160\n",
      "Epoch 00108: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 566.8500 - val_loss: 365.2719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 574.3602\n",
      "Epoch 00109: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 578.3417 - val_loss: 369.9671\n",
      "Epoch 110/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 540.7134\n",
      "Epoch 00110: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 545.0088 - val_loss: 357.2255\n",
      "Epoch 111/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 602.7018\n",
      "Epoch 00111: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 601.0890 - val_loss: 357.8241\n",
      "Epoch 112/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 604.1956\n",
      "Epoch 00112: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 602.5643 - val_loss: 358.2113\n",
      "Epoch 113/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 604.3162\n",
      "Epoch 00113: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 607.2502 - val_loss: 361.8270\n",
      "Epoch 114/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 602.8896\n",
      "Epoch 00114: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 600.8919 - val_loss: 357.3166\n",
      "Epoch 115/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 567.9144\n",
      "Epoch 00115: val_loss did not improve\n",
      "140/140 [==============================] - 19s 133ms/step - loss: 566.7551 - val_loss: 355.1713\n",
      "Epoch 116/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 584.0312\n",
      "Epoch 00116: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 588.7844 - val_loss: 350.2288\n",
      "Epoch 117/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 565.1396\n",
      "Epoch 00117: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 563.6207 - val_loss: 385.8550\n",
      "Epoch 118/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 554.6341\n",
      "Epoch 00118: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 553.2938 - val_loss: 357.1273\n",
      "Epoch 119/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 608.8441\n",
      "Epoch 00119: val_loss did not improve\n",
      "140/140 [==============================] - 20s 145ms/step - loss: 609.9020 - val_loss: 353.3994\n",
      "Epoch 120/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 528.0581\n",
      "Epoch 00120: val_loss improved from 348.84995 to 346.83920, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 19s 133ms/step - loss: 527.3422 - val_loss: 346.8392\n",
      "Epoch 121/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 545.9445\n",
      "Epoch 00121: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 544.8862 - val_loss: 348.7395\n",
      "Epoch 122/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 608.2250\n",
      "Epoch 00122: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 610.0474 - val_loss: 377.9551\n",
      "Epoch 123/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 589.1366\n",
      "Epoch 00123: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 589.9257 - val_loss: 367.9765\n",
      "Epoch 124/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 562.8224\n",
      "Epoch 00124: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 561.4511 - val_loss: 355.9543\n",
      "Epoch 125/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 648.0577\n",
      "Epoch 00125: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 647.1984 - val_loss: 356.4780\n",
      "Epoch 126/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 565.0928\n",
      "Epoch 00126: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 563.6295 - val_loss: 355.3438\n",
      "Epoch 127/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 549.0532\n",
      "Epoch 00127: val_loss did not improve\n",
      "140/140 [==============================] - 18s 131ms/step - loss: 553.1360 - val_loss: 356.8861\n",
      "Epoch 128/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 578.5101\n",
      "Epoch 00128: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 577.1977 - val_loss: 354.4293\n",
      "Epoch 129/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 589.4870\n",
      "Epoch 00129: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 587.9486 - val_loss: 366.9252\n",
      "Epoch 130/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 584.4078\n",
      "Epoch 00130: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 582.9495 - val_loss: 356.4173\n",
      "Epoch 131/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 505.1375\n",
      "Epoch 00131: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 504.4057 - val_loss: 384.2797\n",
      "Epoch 132/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 535.4484\n",
      "Epoch 00132: val_loss did not improve\n",
      "140/140 [==============================] - 18s 131ms/step - loss: 535.9013 - val_loss: 360.2097\n",
      "Epoch 133/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 590.1664\n",
      "Epoch 00133: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 589.4785 - val_loss: 358.9072\n",
      "Epoch 134/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 569.4781\n",
      "Epoch 00134: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 570.5825 - val_loss: 358.5965\n",
      "Epoch 135/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 522.5126\n",
      "Epoch 00135: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 527.1889 - val_loss: 352.3688\n",
      "Epoch 136/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 579.9724\n",
      "Epoch 00136: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 578.2951 - val_loss: 353.4696\n",
      "Epoch 137/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 598.7320\n",
      "Epoch 00137: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 597.6717 - val_loss: 406.5002\n",
      "Epoch 138/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 552.6926\n",
      "Epoch 00138: val_loss did not improve\n",
      "140/140 [==============================] - 19s 133ms/step - loss: 555.1565 - val_loss: 349.4427\n",
      "Epoch 139/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 548.4328\n",
      "Epoch 00139: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 546.9061 - val_loss: 362.3004\n",
      "Epoch 140/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 516.9272\n",
      "Epoch 00140: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 515.6802 - val_loss: 347.3818\n",
      "Epoch 141/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 544.1266\n",
      "Epoch 00141: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 555.9597 - val_loss: 349.8283\n",
      "Epoch 142/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 541.1328\n",
      "Epoch 00142: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 548.8515 - val_loss: 350.9229\n",
      "Epoch 143/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 546.8818\n",
      "Epoch 00143: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 545.5134 - val_loss: 358.1816\n",
      "Epoch 144/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 580.4784\n",
      "Epoch 00144: val_loss improved from 346.83920 to 346.72613, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 578.9415 - val_loss: 346.7261\n",
      "Epoch 145/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 505.3704\n",
      "Epoch 00145: val_loss did not improve\n",
      "140/140 [==============================] - 21s 146ms/step - loss: 504.4667 - val_loss: 351.7141\n",
      "Epoch 146/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/140 [============================>.] - ETA: 0s - loss: 575.8957\n",
      "Epoch 00146: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 574.1788 - val_loss: 350.8902\n",
      "Epoch 147/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 586.7342\n",
      "Epoch 00147: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 584.9522 - val_loss: 353.4242\n",
      "Epoch 148/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 582.2041\n",
      "Epoch 00148: val_loss did not improve\n",
      "140/140 [==============================] - 19s 134ms/step - loss: 580.9110 - val_loss: 377.4475\n",
      "Epoch 149/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 565.8707\n",
      "Epoch 00149: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 564.4796 - val_loss: 348.2888\n",
      "Epoch 150/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 524.8239\n",
      "Epoch 00150: val_loss improved from 346.72613 to 341.89068, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 144ms/step - loss: 523.4947 - val_loss: 341.8907\n",
      "Epoch 151/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 571.8537\n",
      "Epoch 00151: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 570.4248 - val_loss: 354.4091\n",
      "Epoch 152/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 545.1783\n",
      "Epoch 00152: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 544.4587 - val_loss: 350.2033\n",
      "Epoch 153/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 570.9507\n",
      "Epoch 00153: val_loss improved from 341.89068 to 341.72356, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 144ms/step - loss: 577.7726 - val_loss: 341.7236\n",
      "Epoch 154/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 598.9985\n",
      "Epoch 00154: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 597.6931 - val_loss: 351.6575\n",
      "Epoch 155/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 561.1204\n",
      "Epoch 00155: val_loss did not improve\n",
      "140/140 [==============================] - 19s 134ms/step - loss: 559.5560 - val_loss: 352.7521\n",
      "Epoch 156/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 553.9132\n",
      "Epoch 00156: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 552.4399 - val_loss: 347.7258\n",
      "Epoch 157/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 554.2599\n",
      "Epoch 00157: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 553.6137 - val_loss: 341.9661\n",
      "Epoch 158/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 562.7514\n",
      "Epoch 00158: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 561.1171 - val_loss: 349.4428\n",
      "Epoch 159/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 522.2985\n",
      "Epoch 00159: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 521.3616 - val_loss: 348.2580\n",
      "Epoch 160/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 537.7069\n",
      "Epoch 00160: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 536.6060 - val_loss: 346.1686\n",
      "Epoch 161/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 542.7703\n",
      "Epoch 00161: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 541.5087 - val_loss: 348.4603\n",
      "Epoch 162/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 485.2575\n",
      "Epoch 00162: val_loss improved from 341.72356 to 341.27862, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 487.3317 - val_loss: 341.2786\n",
      "Epoch 163/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 502.5604\n",
      "Epoch 00163: val_loss did not improve\n",
      "140/140 [==============================] - 19s 134ms/step - loss: 506.8812 - val_loss: 416.3676\n",
      "Epoch 164/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 577.1573\n",
      "Epoch 00164: val_loss did not improve\n",
      "140/140 [==============================] - 20s 144ms/step - loss: 575.5334 - val_loss: 348.4582\n",
      "Epoch 165/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 557.8166\n",
      "Epoch 00165: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 556.1878 - val_loss: 356.4464\n",
      "Epoch 166/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 566.3649\n",
      "Epoch 00166: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 564.7170 - val_loss: 349.8518\n",
      "Epoch 167/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 545.6127\n",
      "Epoch 00167: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 544.2994 - val_loss: 344.2011\n",
      "Epoch 168/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 484.1340\n",
      "Epoch 00168: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 483.3004 - val_loss: 351.6287\n",
      "Epoch 169/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 557.4785\n",
      "Epoch 00169: val_loss improved from 341.27862 to 341.00037, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 561.6833 - val_loss: 341.0004\n",
      "Epoch 170/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 549.7238\n",
      "Epoch 00170: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 548.2027 - val_loss: 346.4859\n",
      "Epoch 171/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 542.1820\n",
      "Epoch 00171: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 541.0245 - val_loss: 343.8501\n",
      "Epoch 172/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 538.5162\n",
      "Epoch 00172: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 537.0084 - val_loss: 344.5088\n",
      "Epoch 173/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 527.9675\n",
      "Epoch 00173: val_loss did not improve\n",
      "140/140 [==============================] - 19s 133ms/step - loss: 526.6972 - val_loss: 344.6151\n",
      "Epoch 174/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 518.0062\n",
      "Epoch 00174: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 520.5957 - val_loss: 345.7441\n",
      "Epoch 175/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 541.7901\n",
      "Epoch 00175: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 540.5432 - val_loss: 346.4662\n",
      "Epoch 176/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 543.9701\n",
      "Epoch 00176: val_loss improved from 341.00037 to 340.87631, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 139ms/step - loss: 543.6417 - val_loss: 340.8763\n",
      "Epoch 177/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 572.3202\n",
      "Epoch 00177: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 571.0219 - val_loss: 341.9208\n",
      "Epoch 178/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 539.5117\n",
      "Epoch 00178: val_loss did not improve\n",
      "140/140 [==============================] - 20s 144ms/step - loss: 542.6289 - val_loss: 348.7193\n",
      "Epoch 179/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 532.9798\n",
      "Epoch 00179: val_loss did not improve\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 536.0795 - val_loss: 342.0409\n",
      "Epoch 180/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 550.1751\n",
      "Epoch 00180: val_loss improved from 340.87631 to 339.37312, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 139ms/step - loss: 550.7232 - val_loss: 339.3731\n",
      "Epoch 181/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 514.8506\n",
      "Epoch 00181: val_loss did not improve\n",
      "140/140 [==============================] - 20s 144ms/step - loss: 513.5182 - val_loss: 342.4160\n",
      "Epoch 182/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/140 [============================>.] - ETA: 0s - loss: 548.1238\n",
      "Epoch 00182: val_loss did not improve\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 548.1500 - val_loss: 354.0021\n",
      "Epoch 183/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 551.3951\n",
      "Epoch 00183: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 549.8591 - val_loss: 342.2077\n",
      "Epoch 184/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 563.0100\n",
      "Epoch 00184: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 568.0982 - val_loss: 348.5426\n",
      "Epoch 185/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 543.2178\n",
      "Epoch 00185: val_loss did not improve\n",
      "140/140 [==============================] - 20s 145ms/step - loss: 541.6308 - val_loss: 342.5720\n",
      "Epoch 186/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 518.6975\n",
      "Epoch 00186: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 517.8076 - val_loss: 341.9072\n",
      "Epoch 187/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 552.9638\n",
      "Epoch 00187: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 551.3115 - val_loss: 343.4274\n",
      "Epoch 188/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 540.2308\n",
      "Epoch 00188: val_loss improved from 339.37312 to 336.09069, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 21s 148ms/step - loss: 542.4822 - val_loss: 336.0907\n",
      "Epoch 189/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 553.0906\n",
      "Epoch 00189: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 551.8044 - val_loss: 344.8324\n",
      "Epoch 190/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 502.3131\n",
      "Epoch 00190: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 508.1952 - val_loss: 345.6466\n",
      "Epoch 191/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 541.1304\n",
      "Epoch 00191: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 539.4585 - val_loss: 337.3523\n",
      "Epoch 192/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 558.8643\n",
      "Epoch 00192: val_loss improved from 336.09069 to 335.88250, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 557.3262 - val_loss: 335.8825\n",
      "Epoch 193/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 538.9084\n",
      "Epoch 00193: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 540.5645 - val_loss: 336.9353\n",
      "Epoch 194/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 576.0084\n",
      "Epoch 00194: val_loss did not improve\n",
      "140/140 [==============================] - 20s 139ms/step - loss: 575.0922 - val_loss: 343.2821\n",
      "Epoch 195/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 574.2209\n",
      "Epoch 00195: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 572.3094 - val_loss: 341.8509\n",
      "Epoch 196/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 569.7529\n",
      "Epoch 00196: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 568.6105 - val_loss: 340.2571\n",
      "Epoch 197/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 547.9544\n",
      "Epoch 00197: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 546.4638 - val_loss: 336.0338\n",
      "Epoch 198/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 528.4127\n",
      "Epoch 00198: val_loss improved from 335.88250 to 334.46951, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 529.7449 - val_loss: 334.4695\n",
      "Epoch 199/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 544.9803\n",
      "Epoch 00199: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 544.7491 - val_loss: 339.0765\n",
      "Epoch 200/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 524.1712\n",
      "Epoch 00200: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 522.8559 - val_loss: 355.5673\n",
      "Epoch 201/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 505.4111\n",
      "Epoch 00201: val_loss improved from 334.46951 to 330.87526, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 504.2847 - val_loss: 330.8753\n",
      "Epoch 202/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 536.3967\n",
      "Epoch 00202: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 539.2378 - val_loss: 343.5797\n",
      "Epoch 203/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 561.6607\n",
      "Epoch 00203: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 560.1843 - val_loss: 337.0162\n",
      "Epoch 204/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 493.3796\n",
      "Epoch 00204: val_loss did not improve\n",
      "140/140 [==============================] - 18s 130ms/step - loss: 492.1395 - val_loss: 333.5443\n",
      "Epoch 205/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 570.3807\n",
      "Epoch 00205: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 568.8192 - val_loss: 336.7720\n",
      "Epoch 206/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 601.1742\n",
      "Epoch 00206: val_loss did not improve\n",
      "140/140 [==============================] - 19s 134ms/step - loss: 601.2718 - val_loss: 333.4981\n",
      "Epoch 207/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 530.1222\n",
      "Epoch 00207: val_loss did not improve\n",
      "140/140 [==============================] - 19s 134ms/step - loss: 529.8115 - val_loss: 335.1602\n",
      "Epoch 208/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 545.0697\n",
      "Epoch 00208: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 543.5557 - val_loss: 331.5529\n",
      "Epoch 209/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 531.7791\n",
      "Epoch 00209: val_loss did not improve\n",
      "140/140 [==============================] - 20s 139ms/step - loss: 537.6670 - val_loss: 339.2757\n",
      "Epoch 210/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 553.8361\n",
      "Epoch 00210: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 552.3581 - val_loss: 349.3031\n",
      "Epoch 211/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 538.0735\n",
      "Epoch 00211: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 536.7132 - val_loss: 331.1995\n",
      "Epoch 212/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 572.7850\n",
      "Epoch 00212: val_loss improved from 330.87526 to 330.06149, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 570.9556 - val_loss: 330.0615\n",
      "Epoch 213/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 521.0068\n",
      "Epoch 00213: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 519.6675 - val_loss: 336.9708\n",
      "Epoch 214/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 531.7527\n",
      "Epoch 00214: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 530.3541 - val_loss: 341.1314\n",
      "Epoch 215/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 516.3064\n",
      "Epoch 00215: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 519.0830 - val_loss: 334.9492\n",
      "Epoch 216/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 551.2175\n",
      "Epoch 00216: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 549.9113 - val_loss: 334.7545\n",
      "Epoch 217/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 530.8794\n",
      "Epoch 00217: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 529.5247 - val_loss: 337.2766\n",
      "Epoch 218/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 558.5516\n",
      "Epoch 00218: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 556.9334 - val_loss: 332.7622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 525.5641\n",
      "Epoch 00219: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 524.2865 - val_loss: 352.8435\n",
      "Epoch 220/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 562.2508\n",
      "Epoch 00220: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 560.6383 - val_loss: 338.5302\n",
      "Epoch 221/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 522.5713\n",
      "Epoch 00221: val_loss improved from 330.06149 to 327.89793, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 525.5181 - val_loss: 327.8979\n",
      "Epoch 222/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 544.6601\n",
      "Epoch 00222: val_loss did not improve\n",
      "140/140 [==============================] - 18s 131ms/step - loss: 543.4494 - val_loss: 335.8280\n",
      "Epoch 223/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 570.9222\n",
      "Epoch 00223: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 572.2928 - val_loss: 328.5797\n",
      "Epoch 224/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 636.9289\n",
      "Epoch 00224: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 634.5362 - val_loss: 329.8074\n",
      "Epoch 225/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 556.6537\n",
      "Epoch 00225: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 555.3314 - val_loss: 328.1618\n",
      "Epoch 226/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 589.4134\n",
      "Epoch 00226: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 588.8559 - val_loss: 337.1763\n",
      "Epoch 227/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 562.9505\n",
      "Epoch 00227: val_loss improved from 327.89793 to 325.00762, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 561.4519 - val_loss: 325.0076\n",
      "Epoch 228/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 494.7997\n",
      "Epoch 00228: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 493.9579 - val_loss: 329.8366\n",
      "Epoch 229/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 531.9842\n",
      "Epoch 00229: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 530.4193 - val_loss: 334.3738\n",
      "Epoch 230/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 572.1401\n",
      "Epoch 00230: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 570.5602 - val_loss: 330.6596\n",
      "Epoch 231/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 541.2826\n",
      "Epoch 00231: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 539.8993 - val_loss: 328.0352\n",
      "Epoch 232/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 509.0477\n",
      "Epoch 00232: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 513.8104 - val_loss: 331.7084\n",
      "Epoch 233/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 542.2297\n",
      "Epoch 00233: val_loss improved from 325.00762 to 322.88490, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 144ms/step - loss: 548.0900 - val_loss: 322.8849\n",
      "Epoch 234/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 542.4334\n",
      "Epoch 00234: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 541.0141 - val_loss: 331.2786\n",
      "Epoch 235/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 523.7635\n",
      "Epoch 00235: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 522.4004 - val_loss: 330.7602\n",
      "Epoch 236/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 549.8626\n",
      "Epoch 00236: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 552.9178 - val_loss: 341.4019\n",
      "Epoch 237/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 511.0433\n",
      "Epoch 00237: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 509.7669 - val_loss: 328.7214\n",
      "Epoch 238/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 491.0981\n",
      "Epoch 00238: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 489.9324 - val_loss: 324.4365\n",
      "Epoch 239/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 536.8413\n",
      "Epoch 00239: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 535.4131 - val_loss: 336.3526\n",
      "Epoch 240/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 554.6481\n",
      "Epoch 00240: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 553.0449 - val_loss: 325.7291\n",
      "Epoch 241/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 482.6408\n",
      "Epoch 00241: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 481.5411 - val_loss: 329.4588\n",
      "Epoch 242/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 468.3477\n",
      "Epoch 00242: val_loss did not improve\n",
      "140/140 [==============================] - 19s 134ms/step - loss: 468.9383 - val_loss: 326.5433\n",
      "Epoch 243/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 483.9735\n",
      "Epoch 00243: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 486.7073 - val_loss: 329.6566\n",
      "Epoch 244/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 520.5595\n",
      "Epoch 00244: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 519.2193 - val_loss: 335.0959\n",
      "Epoch 245/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 533.4720\n",
      "Epoch 00245: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 532.0660 - val_loss: 332.9484\n",
      "Epoch 246/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 537.6205\n",
      "Epoch 00246: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 542.2500 - val_loss: 330.0156\n",
      "Epoch 247/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 574.7299\n",
      "Epoch 00247: val_loss did not improve\n",
      "140/140 [==============================] - 21s 147ms/step - loss: 573.0471 - val_loss: 330.9837\n",
      "Epoch 248/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 549.4115\n",
      "Epoch 00248: val_loss did not improve\n",
      "140/140 [==============================] - 20s 144ms/step - loss: 549.2654 - val_loss: 324.7726\n",
      "Epoch 249/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 518.8051\n",
      "Epoch 00249: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 520.1779 - val_loss: 335.7060\n",
      "Epoch 250/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 533.1786\n",
      "Epoch 00250: val_loss did not improve\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 533.8520 - val_loss: 325.3246\n",
      "Epoch 251/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 537.5962\n",
      "Epoch 00251: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 536.0474 - val_loss: 332.1344\n",
      "Epoch 252/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 527.0158\n",
      "Epoch 00252: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 525.4465 - val_loss: 333.2195\n",
      "Epoch 253/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 514.0621\n",
      "Epoch 00253: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 512.7577 - val_loss: 327.6712\n",
      "Epoch 254/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 516.0434\n",
      "Epoch 00254: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 517.2093 - val_loss: 332.3800\n",
      "Epoch 255/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 585.8243\n",
      "Epoch 00255: val_loss did not improve\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 590.8498 - val_loss: 333.2593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 256/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 472.3851\n",
      "Epoch 00256: val_loss improved from 322.88490 to 321.25232, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 144ms/step - loss: 471.0809 - val_loss: 321.2523\n",
      "Epoch 257/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 554.3666\n",
      "Epoch 00257: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 552.7628 - val_loss: 323.9467\n",
      "Epoch 258/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 539.6971\n",
      "Epoch 00258: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 539.7487 - val_loss: 326.2043\n",
      "Epoch 259/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 520.8936\n",
      "Epoch 00259: val_loss did not improve\n",
      "140/140 [==============================] - 20s 139ms/step - loss: 520.8067 - val_loss: 326.4853\n",
      "Epoch 260/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 501.7576\n",
      "Epoch 00260: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 510.5343 - val_loss: 323.9577\n",
      "Epoch 261/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 544.1812\n",
      "Epoch 00261: val_loss did not improve\n",
      "140/140 [==============================] - 19s 133ms/step - loss: 545.6637 - val_loss: 328.8232\n",
      "Epoch 262/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 531.5283\n",
      "Epoch 00262: val_loss did not improve\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 530.1657 - val_loss: 324.9856\n",
      "Epoch 263/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 543.8180\n",
      "Epoch 00263: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 542.0853 - val_loss: 327.4195\n",
      "Epoch 264/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 573.9967\n",
      "Epoch 00264: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 572.3978 - val_loss: 325.4342\n",
      "Epoch 265/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 514.3256\n",
      "Epoch 00265: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 512.9684 - val_loss: 329.2553\n",
      "Epoch 266/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 554.3035\n",
      "Epoch 00266: val_loss did not improve\n",
      "140/140 [==============================] - 20s 145ms/step - loss: 552.6106 - val_loss: 325.1250\n",
      "Epoch 267/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 551.2009\n",
      "Epoch 00267: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 549.4687 - val_loss: 325.3210\n",
      "Epoch 268/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 529.5044\n",
      "Epoch 00268: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 532.8115 - val_loss: 323.4928\n",
      "Epoch 269/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 496.9644\n",
      "Epoch 00269: val_loss did not improve\n",
      "140/140 [==============================] - 19s 132ms/step - loss: 496.1796 - val_loss: 322.5478\n",
      "Epoch 270/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 535.9484\n",
      "Epoch 00270: val_loss improved from 321.25232 to 320.65393, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 542.3640 - val_loss: 320.6539\n",
      "Epoch 271/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 464.5819\n",
      "Epoch 00271: val_loss improved from 320.65393 to 317.31575, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 464.2844 - val_loss: 317.3158\n",
      "Epoch 272/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 496.0761\n",
      "Epoch 00272: val_loss did not improve\n",
      "140/140 [==============================] - 18s 130ms/step - loss: 495.0736 - val_loss: 323.2528\n",
      "Epoch 273/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 502.8493\n",
      "Epoch 00273: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 501.5561 - val_loss: 322.3926\n",
      "Epoch 274/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 522.7787\n",
      "Epoch 00274: val_loss did not improve\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 525.1064 - val_loss: 336.5890\n",
      "Epoch 275/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 550.2831\n",
      "Epoch 00275: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 548.9350 - val_loss: 335.3554\n",
      "Epoch 276/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 570.9716\n",
      "Epoch 00276: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 569.6473 - val_loss: 329.9457\n",
      "Epoch 277/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 514.3681\n",
      "Epoch 00277: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 512.8743 - val_loss: 329.8103\n",
      "Epoch 278/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 474.4217\n",
      "Epoch 00278: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 473.5982 - val_loss: 348.3620\n",
      "Epoch 279/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 477.6577\n",
      "Epoch 00279: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 476.5442 - val_loss: 318.1374\n",
      "Epoch 280/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 559.7712\n",
      "Epoch 00280: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 558.1233 - val_loss: 327.3394\n",
      "Epoch 281/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 540.4766\n",
      "Epoch 00281: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 538.7951 - val_loss: 322.1641\n",
      "Epoch 282/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 516.2800\n",
      "Epoch 00282: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 516.2809 - val_loss: 331.6786\n",
      "Epoch 283/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 515.2347\n",
      "Epoch 00283: val_loss improved from 317.31575 to 316.87755, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 513.9272 - val_loss: 316.8776\n",
      "Epoch 284/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 541.8432\n",
      "Epoch 00284: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 540.2139 - val_loss: 323.2423\n",
      "Epoch 285/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 534.1699\n",
      "Epoch 00285: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 532.6495 - val_loss: 320.9193\n",
      "Epoch 286/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 576.8906\n",
      "Epoch 00286: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 575.4416 - val_loss: 328.2300\n",
      "Epoch 287/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 529.2471\n",
      "Epoch 00287: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 527.6729 - val_loss: 320.2314\n",
      "Epoch 288/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 550.5196\n",
      "Epoch 00288: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 548.7219 - val_loss: 320.8767\n",
      "Epoch 289/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 491.2233\n",
      "Epoch 00289: val_loss did not improve\n",
      "140/140 [==============================] - 19s 134ms/step - loss: 492.0679 - val_loss: 319.9424\n",
      "Epoch 290/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 529.9991\n",
      "Epoch 00290: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 528.7913 - val_loss: 320.7172\n",
      "Epoch 291/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 474.6805\n",
      "Epoch 00291: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 475.7274 - val_loss: 327.6484\n",
      "Epoch 292/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 488.3794\n",
      "Epoch 00292: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 487.3766 - val_loss: 322.6348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 510.7407\n",
      "Epoch 00293: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 514.5843 - val_loss: 328.2489\n",
      "Epoch 294/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 499.0690\n",
      "Epoch 00294: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 502.2866 - val_loss: 328.3880\n",
      "Epoch 295/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 535.8858\n",
      "Epoch 00295: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 535.9470 - val_loss: 325.5408\n",
      "Epoch 296/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 561.1371\n",
      "Epoch 00296: val_loss did not improve\n",
      "140/140 [==============================] - 20s 144ms/step - loss: 559.4958 - val_loss: 328.8693\n",
      "Epoch 297/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 529.6653\n",
      "Epoch 00297: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 527.8418 - val_loss: 320.0529\n",
      "Epoch 298/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 526.1680\n",
      "Epoch 00298: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 528.3236 - val_loss: 321.4825\n",
      "Epoch 299/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 552.2889\n",
      "Epoch 00299: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 557.6200 - val_loss: 318.8471\n",
      "Epoch 300/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 543.0787\n",
      "Epoch 00300: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 548.6599 - val_loss: 324.2170\n",
      "Epoch 301/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 493.4177\n",
      "Epoch 00301: val_loss did not improve\n",
      "140/140 [==============================] - 19s 133ms/step - loss: 493.1401 - val_loss: 321.5110\n",
      "Epoch 302/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 536.6247\n",
      "Epoch 00302: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 534.9916 - val_loss: 317.5231\n",
      "Epoch 303/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 561.4973\n",
      "Epoch 00303: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 559.9977 - val_loss: 323.5070\n",
      "Epoch 304/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 483.8012\n",
      "Epoch 00304: val_loss improved from 316.87755 to 312.87535, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 482.7891 - val_loss: 312.8754\n",
      "Epoch 305/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 571.6269\n",
      "Epoch 00305: val_loss did not improve\n",
      "140/140 [==============================] - 19s 134ms/step - loss: 569.7309 - val_loss: 316.5494\n",
      "Epoch 306/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 534.5768\n",
      "Epoch 00306: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 538.0221 - val_loss: 330.4260\n",
      "Epoch 307/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 513.8306\n",
      "Epoch 00307: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 512.1623 - val_loss: 321.3000\n",
      "Epoch 308/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 521.5320\n",
      "Epoch 00308: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 520.2427 - val_loss: 331.7820\n",
      "Epoch 309/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 483.1508\n",
      "Epoch 00309: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 482.5988 - val_loss: 322.1005\n",
      "Epoch 310/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 479.2661\n",
      "Epoch 00310: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 478.0554 - val_loss: 318.4323\n",
      "Epoch 311/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 475.3017\n",
      "Epoch 00311: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 475.1252 - val_loss: 323.8906\n",
      "Epoch 312/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 492.0095\n",
      "Epoch 00312: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 497.2443 - val_loss: 329.3253\n",
      "Epoch 313/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 513.0247\n",
      "Epoch 00313: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 511.6898 - val_loss: 316.0700\n",
      "Epoch 314/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 507.6841\n",
      "Epoch 00314: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 508.3318 - val_loss: 321.8096\n",
      "Epoch 315/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 539.9341\n",
      "Epoch 00315: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 538.2994 - val_loss: 323.5287\n",
      "Epoch 316/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 534.2330\n",
      "Epoch 00316: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 532.6367 - val_loss: 342.5401\n",
      "Epoch 317/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 538.8219\n",
      "Epoch 00317: val_loss did not improve\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 543.5290 - val_loss: 323.9474\n",
      "Epoch 318/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 471.6073\n",
      "Epoch 00318: val_loss did not improve\n",
      "140/140 [==============================] - 20s 144ms/step - loss: 472.7565 - val_loss: 325.4959\n",
      "Epoch 319/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 492.1198\n",
      "Epoch 00319: val_loss did not improve\n",
      "140/140 [==============================] - 19s 133ms/step - loss: 490.7747 - val_loss: 323.9011\n",
      "Epoch 320/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 530.9136\n",
      "Epoch 00320: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 529.2742 - val_loss: 318.6343\n",
      "Epoch 321/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 537.9684\n",
      "Epoch 00321: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 541.8424 - val_loss: 324.0666\n",
      "Epoch 322/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 497.5315\n",
      "Epoch 00322: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 500.6067 - val_loss: 322.4934\n",
      "Epoch 323/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 496.8054\n",
      "Epoch 00323: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 495.5666 - val_loss: 320.9618\n",
      "Epoch 324/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 481.0826\n",
      "Epoch 00324: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 480.0532 - val_loss: 317.9180\n",
      "Epoch 325/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 490.5681\n",
      "Epoch 00325: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 489.0917 - val_loss: 316.5550\n",
      "Epoch 326/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 514.6757\n",
      "Epoch 00326: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 515.7345 - val_loss: 333.5184\n",
      "Epoch 327/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 484.0455\n",
      "Epoch 00327: val_loss did not improve\n",
      "140/140 [==============================] - 19s 134ms/step - loss: 487.3404 - val_loss: 323.9501\n",
      "Epoch 328/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 614.1203\n",
      "Epoch 00328: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 611.7480 - val_loss: 323.0795\n",
      "Epoch 329/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 541.0011\n",
      "Epoch 00329: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 539.6447 - val_loss: 313.6025\n",
      "Epoch 330/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 578.6111\n",
      "Epoch 00330: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 576.8520 - val_loss: 314.9325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 527.5225\n",
      "Epoch 00331: val_loss did not improve\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 525.9245 - val_loss: 319.9382\n",
      "Epoch 332/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 509.5354\n",
      "Epoch 00332: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 509.2631 - val_loss: 319.3438\n",
      "Epoch 333/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 582.5602\n",
      "Epoch 00333: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 580.6001 - val_loss: 322.6312\n",
      "Epoch 334/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 535.7279\n",
      "Epoch 00334: val_loss improved from 312.87535 to 310.79357, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 146ms/step - loss: 534.0094 - val_loss: 310.7936\n",
      "Epoch 335/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 524.0779\n",
      "Epoch 00335: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 522.7036 - val_loss: 317.8663\n",
      "Epoch 336/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 541.5032\n",
      "Epoch 00336: val_loss did not improve\n",
      "140/140 [==============================] - 19s 133ms/step - loss: 540.0389 - val_loss: 318.9808\n",
      "Epoch 337/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 489.8752\n",
      "Epoch 00337: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 488.4994 - val_loss: 319.2540\n",
      "Epoch 338/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 563.6462\n",
      "Epoch 00338: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 570.6726 - val_loss: 315.4557\n",
      "Epoch 339/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 497.7655\n",
      "Epoch 00339: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 500.8723 - val_loss: 318.9508\n",
      "Epoch 340/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 527.1199\n",
      "Epoch 00340: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 532.8494 - val_loss: 317.2302\n",
      "Epoch 341/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 466.5320\n",
      "Epoch 00341: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 465.5844 - val_loss: 321.9011\n",
      "Epoch 342/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 538.6144\n",
      "Epoch 00342: val_loss did not improve\n",
      "140/140 [==============================] - 20s 139ms/step - loss: 536.9017 - val_loss: 313.7268\n",
      "Epoch 343/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 531.0767\n",
      "Epoch 00343: val_loss did not improve\n",
      "140/140 [==============================] - 20s 139ms/step - loss: 530.6460 - val_loss: 328.4511\n",
      "Epoch 344/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 554.3617\n",
      "Epoch 00344: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 559.2374 - val_loss: 320.3847\n",
      "Epoch 345/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 592.3970\n",
      "Epoch 00345: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 598.5667 - val_loss: 322.7716\n",
      "Epoch 346/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 576.6589\n",
      "Epoch 00346: val_loss did not improve\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 574.7640 - val_loss: 319.4315\n",
      "Epoch 347/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 573.2890\n",
      "Epoch 00347: val_loss did not improve\n",
      "140/140 [==============================] - 19s 133ms/step - loss: 571.3998 - val_loss: 313.8725\n",
      "Epoch 348/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 534.7957\n",
      "Epoch 00348: val_loss did not improve\n",
      "140/140 [==============================] - 20s 146ms/step - loss: 533.4859 - val_loss: 320.5467\n",
      "Epoch 349/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 511.3065\n",
      "Epoch 00349: val_loss did not improve\n",
      "140/140 [==============================] - 19s 133ms/step - loss: 516.6402 - val_loss: 318.8703\n",
      "Epoch 350/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 485.0064\n",
      "Epoch 00350: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 483.6939 - val_loss: 318.5649\n",
      "Epoch 351/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 478.7585\n",
      "Epoch 00351: val_loss did not improve\n",
      "140/140 [==============================] - 18s 131ms/step - loss: 477.6049 - val_loss: 316.3564\n",
      "Epoch 352/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 572.9700\n",
      "Epoch 00352: val_loss did not improve\n",
      "140/140 [==============================] - 19s 134ms/step - loss: 571.1143 - val_loss: 324.3570\n",
      "Epoch 353/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 464.9492\n",
      "Epoch 00353: val_loss did not improve\n",
      "140/140 [==============================] - 18s 131ms/step - loss: 469.1298 - val_loss: 312.2036\n",
      "Epoch 354/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 473.5290\n",
      "Epoch 00354: val_loss did not improve\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 473.7978 - val_loss: 321.9938\n",
      "Epoch 355/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 516.2861\n",
      "Epoch 00355: val_loss improved from 310.79357 to 309.71407, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 143ms/step - loss: 525.1949 - val_loss: 309.7141\n",
      "Epoch 356/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 534.0852\n",
      "Epoch 00356: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 533.0042 - val_loss: 321.5671\n",
      "Epoch 357/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 536.1671\n",
      "Epoch 00357: val_loss did not improve\n",
      "140/140 [==============================] - 19s 134ms/step - loss: 534.5749 - val_loss: 314.1876\n",
      "Epoch 358/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 516.6411\n",
      "Epoch 00358: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 518.5743 - val_loss: 318.8172\n",
      "Epoch 359/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 522.7854\n",
      "Epoch 00359: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 521.1371 - val_loss: 313.3713\n",
      "Epoch 360/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 536.4143\n",
      "Epoch 00360: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 534.7384 - val_loss: 320.5560\n",
      "Epoch 361/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 535.4678\n",
      "Epoch 00361: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 533.8264 - val_loss: 315.0373\n",
      "Epoch 362/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 496.6001\n",
      "Epoch 00362: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 495.5029 - val_loss: 318.8725\n",
      "Epoch 363/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 564.7579\n",
      "Epoch 00363: val_loss improved from 309.71407 to 308.48409, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 146ms/step - loss: 563.0640 - val_loss: 308.4841\n",
      "Epoch 364/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 501.6942\n",
      "Epoch 00364: val_loss did not improve\n",
      "140/140 [==============================] - 19s 134ms/step - loss: 501.5374 - val_loss: 316.2866\n",
      "Epoch 365/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 499.7980\n",
      "Epoch 00365: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 498.5204 - val_loss: 320.2445\n",
      "Epoch 366/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 498.9037\n",
      "Epoch 00366: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 500.2052 - val_loss: 315.3925\n",
      "Epoch 367/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 525.3641\n",
      "Epoch 00367: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 523.7204 - val_loss: 318.5146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 486.1566\n",
      "Epoch 00368: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 484.9222 - val_loss: 319.8647\n",
      "Epoch 369/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 497.4895\n",
      "Epoch 00369: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 497.6691 - val_loss: 355.5073\n",
      "Epoch 370/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 497.2555\n",
      "Epoch 00370: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 498.2540 - val_loss: 312.4695\n",
      "Epoch 371/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 511.4736\n",
      "Epoch 00371: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 510.3159 - val_loss: 321.4042\n",
      "Epoch 372/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 524.3919\n",
      "Epoch 00372: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 524.1215 - val_loss: 322.0002\n",
      "Epoch 373/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 491.9778\n",
      "Epoch 00373: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 495.6426 - val_loss: 316.5754\n",
      "Epoch 374/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 516.5052\n",
      "Epoch 00374: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 520.2895 - val_loss: 318.6813\n",
      "Epoch 375/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 555.6421\n",
      "Epoch 00375: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 554.8090 - val_loss: 323.5966\n",
      "Epoch 376/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 506.0456\n",
      "Epoch 00376: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 504.7665 - val_loss: 315.7419\n",
      "Epoch 377/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 530.6791\n",
      "Epoch 00377: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 529.0895 - val_loss: 320.7615\n",
      "Epoch 378/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 502.2626\n",
      "Epoch 00378: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 500.7276 - val_loss: 312.0587\n",
      "Epoch 379/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 470.3650\n",
      "Epoch 00379: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 469.6297 - val_loss: 316.6443\n",
      "Epoch 380/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 498.6363\n",
      "Epoch 00380: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 508.1933 - val_loss: 314.3875\n",
      "Epoch 381/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 504.3060\n",
      "Epoch 00381: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 503.5831 - val_loss: 318.1647\n",
      "Epoch 382/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 539.4217\n",
      "Epoch 00382: val_loss did not improve\n",
      "140/140 [==============================] - 20s 144ms/step - loss: 537.7177 - val_loss: 319.7368\n",
      "Epoch 383/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 506.2547\n",
      "Epoch 00383: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 508.6761 - val_loss: 317.5362\n",
      "Epoch 384/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 521.2279\n",
      "Epoch 00384: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 519.7215 - val_loss: 315.5334\n",
      "Epoch 385/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 498.4730\n",
      "Epoch 00385: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 498.1618 - val_loss: 319.2176\n",
      "Epoch 386/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 534.7093\n",
      "Epoch 00386: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 533.3550 - val_loss: 315.4949\n",
      "Epoch 387/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 513.3615\n",
      "Epoch 00387: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 511.9863 - val_loss: 316.1759\n",
      "Epoch 388/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 543.6871\n",
      "Epoch 00388: val_loss improved from 308.48409 to 306.17493, saving model to weights/catGen.hdf5\n",
      "140/140 [==============================] - 20s 145ms/step - loss: 549.3575 - val_loss: 306.1749\n",
      "Epoch 389/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 545.3424\n",
      "Epoch 00389: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 543.6399 - val_loss: 319.2093\n",
      "Epoch 390/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 480.1747\n",
      "Epoch 00390: val_loss did not improve\n",
      "140/140 [==============================] - 19s 134ms/step - loss: 479.6650 - val_loss: 316.4785\n",
      "Epoch 391/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 474.3972\n",
      "Epoch 00391: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 473.2879 - val_loss: 318.1130\n",
      "Epoch 392/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 536.6010\n",
      "Epoch 00392: val_loss did not improve\n",
      "140/140 [==============================] - 20s 144ms/step - loss: 537.2158 - val_loss: 327.5223\n",
      "Epoch 393/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 512.9624\n",
      "Epoch 00393: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 518.1642 - val_loss: 311.3229\n",
      "Epoch 394/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 532.6877\n",
      "Epoch 00394: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 532.5280 - val_loss: 327.4909\n",
      "Epoch 395/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 476.9871\n",
      "Epoch 00395: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 475.8930 - val_loss: 311.5267\n",
      "Epoch 396/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 459.4819\n",
      "Epoch 00396: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 459.8472 - val_loss: 308.4904\n",
      "Epoch 397/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 517.0761\n",
      "Epoch 00397: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 515.4433 - val_loss: 320.6693\n",
      "Epoch 398/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 505.1147\n",
      "Epoch 00398: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 503.5007 - val_loss: 316.0781\n",
      "Epoch 399/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 565.1969\n",
      "Epoch 00399: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 568.3311 - val_loss: 320.7388\n",
      "Epoch 400/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 481.2875\n",
      "Epoch 00400: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 484.6594 - val_loss: 332.2533\n",
      "Epoch 401/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 472.2031\n",
      "Epoch 00401: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 470.8683 - val_loss: 317.8383\n",
      "Epoch 402/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 558.2309\n",
      "Epoch 00402: val_loss did not improve\n",
      "140/140 [==============================] - 20s 146ms/step - loss: 556.3116 - val_loss: 313.9419\n",
      "Epoch 403/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 517.0633\n",
      "Epoch 00403: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 518.9521 - val_loss: 317.3714\n",
      "Epoch 404/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 495.0914\n",
      "Epoch 00404: val_loss did not improve\n",
      "140/140 [==============================] - 19s 133ms/step - loss: 493.6661 - val_loss: 317.8752\n",
      "Epoch 405/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 497.3861\n",
      "Epoch 00405: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 501.8287 - val_loss: 323.5590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 406/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 589.0140\n",
      "Epoch 00406: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 587.0364 - val_loss: 321.7775\n",
      "Epoch 407/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 494.9768\n",
      "Epoch 00407: val_loss did not improve\n",
      "140/140 [==============================] - 19s 134ms/step - loss: 493.7542 - val_loss: 312.5618\n",
      "Epoch 408/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 520.5290\n",
      "Epoch 00408: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 519.0777 - val_loss: 314.9727\n",
      "Epoch 409/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 570.1756\n",
      "Epoch 00409: val_loss did not improve\n",
      "140/140 [==============================] - 20s 144ms/step - loss: 568.4228 - val_loss: 316.0596\n",
      "Epoch 410/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 501.9301\n",
      "Epoch 00410: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 500.5820 - val_loss: 317.6938\n",
      "Epoch 411/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 501.6538\n",
      "Epoch 00411: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 500.4201 - val_loss: 312.8012\n",
      "Epoch 412/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 539.0627\n",
      "Epoch 00412: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 539.5633 - val_loss: 319.0377\n",
      "Epoch 413/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 538.6148\n",
      "Epoch 00413: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 537.0149 - val_loss: 312.6142\n",
      "Epoch 414/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 526.9827\n",
      "Epoch 00414: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 525.4816 - val_loss: 322.9748\n",
      "Epoch 415/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 471.5944\n",
      "Epoch 00415: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 471.5521 - val_loss: 321.2560\n",
      "Epoch 416/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 504.6061\n",
      "Epoch 00416: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 503.0519 - val_loss: 313.0694\n",
      "Epoch 417/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 516.9098\n",
      "Epoch 00417: val_loss did not improve\n",
      "140/140 [==============================] - 20s 139ms/step - loss: 515.4658 - val_loss: 316.6249\n",
      "Epoch 418/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 541.1373\n",
      "Epoch 00418: val_loss did not improve\n",
      "140/140 [==============================] - 19s 135ms/step - loss: 539.3500 - val_loss: 318.3042\n",
      "Epoch 419/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 492.9557\n",
      "Epoch 00419: val_loss did not improve\n",
      "140/140 [==============================] - 19s 136ms/step - loss: 491.5465 - val_loss: 312.0547\n",
      "Epoch 420/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 483.7785\n",
      "Epoch 00420: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 482.5584 - val_loss: 310.0817\n",
      "Epoch 421/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 491.7909\n",
      "Epoch 00421: val_loss did not improve\n",
      "140/140 [==============================] - 19s 134ms/step - loss: 490.4391 - val_loss: 320.9390\n",
      "Epoch 422/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 549.4560\n",
      "Epoch 00422: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 547.7211 - val_loss: 308.5963\n",
      "Epoch 423/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 499.0327\n",
      "Epoch 00423: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 502.0663 - val_loss: 316.5285\n",
      "Epoch 424/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 479.5511\n",
      "Epoch 00424: val_loss did not improve\n",
      "140/140 [==============================] - 19s 133ms/step - loss: 478.2471 - val_loss: 315.5556\n",
      "Epoch 425/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 539.1130\n",
      "Epoch 00425: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 537.3976 - val_loss: 313.7187\n",
      "Epoch 426/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 549.4378\n",
      "Epoch 00426: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 555.2902 - val_loss: 309.8303\n",
      "Epoch 427/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 554.5665\n",
      "Epoch 00427: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 552.8108 - val_loss: 319.4334\n",
      "Epoch 428/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 518.0482\n",
      "Epoch 00428: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 516.3677 - val_loss: 321.6488\n",
      "Epoch 429/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 520.1852\n",
      "Epoch 00429: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 522.6222 - val_loss: 317.2057\n",
      "Epoch 430/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 547.8871\n",
      "Epoch 00430: val_loss did not improve\n",
      "140/140 [==============================] - 19s 139ms/step - loss: 546.0756 - val_loss: 316.5900\n",
      "Epoch 431/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 522.1190\n",
      "Epoch 00431: val_loss did not improve\n",
      "140/140 [==============================] - 20s 141ms/step - loss: 521.5159 - val_loss: 311.8610\n",
      "Epoch 432/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 537.7741\n",
      "Epoch 00432: val_loss did not improve\n",
      "140/140 [==============================] - 20s 140ms/step - loss: 540.2343 - val_loss: 312.6428\n",
      "Epoch 433/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 582.8938\n",
      "Epoch 00433: val_loss did not improve\n",
      "140/140 [==============================] - 20s 142ms/step - loss: 583.1651 - val_loss: 321.6000\n",
      "Epoch 434/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 517.5666\n",
      "Epoch 00434: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 522.9955 - val_loss: 313.9999\n",
      "Epoch 435/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 509.8015\n",
      "Epoch 00435: val_loss did not improve\n",
      "140/140 [==============================] - 19s 137ms/step - loss: 517.6782 - val_loss: 311.1020\n",
      "Epoch 436/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 517.7951\n",
      "Epoch 00436: val_loss did not improve\n",
      "140/140 [==============================] - 19s 134ms/step - loss: 517.1671 - val_loss: 312.1797\n",
      "Epoch 437/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 466.6771\n",
      "Epoch 00437: val_loss did not improve\n",
      "140/140 [==============================] - 18s 132ms/step - loss: 465.4492 - val_loss: 328.1256\n",
      "Epoch 438/5000\n",
      "139/140 [============================>.] - ETA: 0s - loss: 496.5184\n",
      "Epoch 00438: val_loss did not improve\n",
      "140/140 [==============================] - 19s 138ms/step - loss: 495.0567 - val_loss: 320.9595\n",
      "Epoch 00438: early stopping\n"
     ]
    }
   ],
   "source": [
    "if ( not trainFresh ):\n",
    "    VAE.load_weights( \"weights/catGen.hdf5\" )\n",
    "\n",
    "earlyStopper = EarlyStopping( patience = 50, verbose = 1 )\n",
    "checkPointer = ModelCheckpoint( filepath = \"weights/catGen.hdf5\", save_best_only = True, verbose = 1 )\n",
    "rateReduce   = ReduceLROnPlateau( monitor = 'val_loss', factor = 0.5, patience = 20, cooldown = 5 )\n",
    "\n",
    "losses = VAE.fit_generator( genBatch( train, batchSize, imgSize, True ),\n",
    "                   validation_data = genBatch( val, batchSize, imgSize, False ),\n",
    "                   epochs = 5000,\n",
    "                   validation_steps = len(val)   // batchSize,\n",
    "                   steps_per_epoch  = len(train) // batchSize,\n",
    "                   callbacks = [ earlyStopper, checkPointer ] )\n",
    "                   #callbacks = [ earlyStopper, checkPointer, rateReduce ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotLosses( losses.history )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
